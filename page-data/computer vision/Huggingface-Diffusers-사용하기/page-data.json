{"componentChunkName":"component---src-templates-blog-post-js","path":"/computer vision/Huggingface-Diffusers-사용하기/","result":{"data":{"site":{"siteMetadata":{"title":"JooWorld","author":"hangjoo","siteUrl":"https://hangjoo.github.io","comment":{"disqusShortName":"","utterances":"hangjoo/utterances-comment"},"sponsor":{"buyMeACoffeeId":"jbee"}}},"markdownRemark":{"id":"8850b76e-b1c3-5365-9de3-5baa068e64e3","excerpt":"Introduction 요즘 이미지 생성 분야에서 diffusion 구조를 사용한 text-to-image 모델의 인기가 뜨겁습니다. Stability AI 사에서 Stable Diffusion을 오픈소스 라이선스로 배포하면서 누구나 쉽게 좋은 성능의 이미지 생성 모델을 사용할 수 있게 되면서 그 인기는 한층 증폭되었습니다. 이에 맞춰 huggingface에서도 사전학습된 diffusion…","html":"<h1 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h1>\n<p>요즘 이미지 생성 분야에서 diffusion 구조를 사용한 text-to-image 모델의 인기가 뜨겁습니다. Stability AI 사에서 Stable Diffusion을 오픈소스 라이선스로 배포하면서 누구나 쉽게 좋은 성능의 이미지 생성 모델을 사용할 수 있게 되면서 그 인기는 한층 증폭되었습니다.</p>\n<p>이에 맞춰 huggingface에서도 사전학습된 diffusion 모델들을 사용할 수 있도록 <code class=\"language-text\">Diffusers</code>라는 라이브러리를 선보였습니다. 이미 자연어 처리 분야에서 대표 플랫폼으로 자리잡은 huggingface답게 stable duffision을 포함하여 많은 사전 학습 모델들을 제공하고 있으며, 단순 추론 외에도 메모리 최적화나 학습 방법 가이드까지 제공하고 있습니다. 특히 diffusion 구조가 기존 모델과 다르게 일반 사용자도 충분히 추론이 가능한 점을 살려 애플 실리콘 환경에서도 실행 가이드를 제공하고 있다는 점이 인상적입니다.</p>\n<p>이미 깃허브 레포지토리의 스타 수가 9.8k를 넘어선 hugginface의 <code class=\"language-text\">diffusers</code>가 이미 이미지 생성 분야에서 하나의 대표 라이브러리로 자리 매김한 이 시점에 여러 diffusion 모델을 사용하면서 알아두면 좋을 정보들을 정리하고자 합니다.</p>\n<h1 id=\"features\" style=\"position:relative;\"><a href=\"#features\" aria-label=\"features permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Features</h1>\n<p>공식 문서에서 따르면 <code class=\"language-text\">Diffusers</code>가 제공하는 기능들은 다음과 같습니다.</p>\n<ul>\n<li>몇 줄의 코드만으로 추론이 가능한 SOTA를 기록한 diffusion 모델 파이프라인을 제공합니다. 또 지원하는 파이프라인에 관한 설명과 관련된 문서도 제공합니다.</li>\n<li>추론 시 속도와 퀄리티의 트레이드-오프(trade-off)를 위해 교대로 사용할 수 있는 다양한 노이즈 스케줄러를 제공합니다.</li>\n<li>end-to-end diffusion 구조 내부에서 사용되는 다양한 종류의 모델(ex. U-Net)을 제공합니다.</li>\n<li>사용될 수 있는 여러 분야에서 diffusion 모델을 학습하는 방법을 제공합니다.</li>\n</ul>\n<h1 id=\"installation\" style=\"position:relative;\"><a href=\"#installation\" aria-label=\"installation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Installation</h1>\n<p>공식 문서에 따르면, <code class=\"language-text\">diffusers</code> 라이브러리는 3.7 이상 버전의 Python, 1.7.0 이상 버전의 PyTorch 그리고 flax가 설치된 환경에서 테스트되었다고 합니다. 그리고 가상 환경에서 설치할 것을 권고하고 있습니다.</p>\n<p>이에 맞춰 diffusers 사용을 위한 가상 환경 하나를 생성하고, PyTorch와 Diffusers, 그리고 transformers를 설치합니다.</p>\n<h2 id=\"1-가상환경-생성\" style=\"position:relative;\"><a href=\"#1-%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD-%EC%83%9D%EC%84%B1\" aria-label=\"1 가상환경 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 가상환경 생성</h2>\n<p>Conda를 사용하여 Python 3.8이 설치된 가상 환경을 생성합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">conda create -n diffusers python=3.8\nconda activate diffusers</code></pre></div>\n<h2 id=\"2-pytorch-설치\" style=\"position:relative;\"><a href=\"#2-pytorch-%EC%84%A4%EC%B9%98\" aria-label=\"2 pytorch 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. PyTorch 설치</h2>\n<p><a href=\"https://pytorch.org/get-started/locally/\">PyTorch 공식 문서</a>를 참고하여 설치합니다. 저는 맥을 사용하고 있기 때문에 따로 cudatoolkit은 설치하지 않고 아래와 같은 명령어로 최신 버전의 PyTorch를 설치합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">conda install pytorch torchvision torchaudio -c pytorch\n\nconda list | grep pytorch  # PyTorch 설치 확인</code></pre></div>\n<h2 id=\"3-transformers-설치\" style=\"position:relative;\"><a href=\"#3-transformers-%EC%84%A4%EC%B9%98\" aria-label=\"3 transformers 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Transformers 설치</h2>\n<p>공식 문서의 설치 가이드에는 별도로 나와있지 않지만 대부분의 Diffusion 모델을 사용하기 위해 필요합니다. 다음과 같이 pip 명령어를 사용하여 설치합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">pip install transformers</code></pre></div>\n<h2 id=\"4-diffusers-설치\" style=\"position:relative;\"><a href=\"#4-diffusers-%EC%84%A4%EC%B9%98\" aria-label=\"4 diffusers 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Diffusers 설치</h2>\n<p><a href=\"https://huggingface.co/docs/diffusers/main/en/installation#install-with-pip\">Diffusers 공식 문서</a>에 따라 pip 명령어로 다음과 같이 설치합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">pip install \"diffusers[torch]\"</code></pre></div>\n<h1 id=\"usage\" style=\"position:relative;\"><a href=\"#usage\" aria-label=\"usage permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Usage</h1>\n<h2 id=\"diffusion-pipeline\" style=\"position:relative;\"><a href=\"#diffusion-pipeline\" aria-label=\"diffusion pipeline permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Diffusion Pipeline</h2>\n<p><code class=\"language-text\">DiffusionPipeline</code>은 추론 시에 사전 학습된 Diffusion 모델을 손쉽게 사용할 수 있는 방법입니다. Diffusion Pipeline은 다음과 같은 task를 지원합니다.</p>\n<table>\n<thead>\n<tr>\n<th>Task</th>\n<th>Description</th>\n<th>Pipeline</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Unconditional Image Generation</td>\n<td>가우시안 노이즈로부터 이미지를 생성합니다.</td>\n<td><a href=\"https://huggingface.co/docs/diffusers/main/en/using-diffusers/unconditional_image_generation\">unconditional_image_generation</a></td>\n</tr>\n<tr>\n<td>Text-Guided Image Generation</td>\n<td>주어진 텍스트 프롬프트로부터 이미지를 생성합니다.</td>\n<td><a href=\"https://huggingface.co/docs/diffusers/main/en/using-diffusers/conditional_image_generation\">conditional_image_generation</a></td>\n</tr>\n<tr>\n<td>Text-Guided Image-to-Image Translation</td>\n<td>주어진 텍스트 프롬프트를 사용하여 이미지를 변환시킵니다.</td>\n<td><a href=\"https://huggingface.co/docs/diffusers/main/en/using-diffusers/img2img%3E\">img2img</a></td>\n</tr>\n<tr>\n<td>Text-Guided Image-Inpainting</td>\n<td>주어진 텍스트 프롬프트와 인페인팅 시 사용되는 마스크를 사용하여 이미지의 마스킹 된 부분을 그립니다.</td>\n<td><a href=\"https://huggingface.co/docs/diffusers/main/en/using-diffusers/inpaint\">inpaint</a></td>\n</tr>\n<tr>\n<td>Text-Guided Depth-to-Image Translation</td>\n<td>깊이 추정을 통해 구조를 보존하면서 텍스트 프롬프트를 이용해 이미지를 변환시킵니다.</td>\n<td><a href=\"https://huggingface.co/docs/diffusers/main/en/using-diffusers/depth2img\">depth2image</a></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"inference\" style=\"position:relative;\"><a href=\"#inference\" aria-label=\"inference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inference</h2>\n<p>위에서 설명한 <code class=\"language-text\">DiffusionPipeline</code>을 사용하여 요즘 핫한 <code class=\"language-text\">Stable Diffusion</code> 모델을 불러와 프롬프트를 사용하여 이미지를 생성하도록 하겠습니다.</p>\n<p>먼저 <code class=\"language-text\">Stable Diffusion</code> 모델을 불러옵니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> diffusers <span class=\"token keyword\">import</span> DiffusionPipeline\n\npipeline <span class=\"token operator\">=</span> DiffusionPipeline<span class=\"token punctuation\">.</span>from_pretrained<span class=\"token punctuation\">(</span><span class=\"token string\">\"runwayml/stable-diffusion-v1-5\"</span><span class=\"token punctuation\">)</span>\npipeline<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">\"mps\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># GPU 사용 시 \"cuda\"</span></code></pre></div>\n<p>그리고 프롬프트(prompt)를 사용하여 이미지를 생성한 뒤 저장합니다. <em>(맥북 M1 프로 기준 80초 정도 소요됩니다)</em></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">image <span class=\"token operator\">=</span> pipeline<span class=\"token punctuation\">(</span><span class=\"token string\">\"An image of a squirrel in Picasso style\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>images<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\nimage<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">\"stable-diffusion-output.png\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>생성된 이미지는 아래와 같습니다.</p>\n<p><img src=\"./Huggingface-Diffusers-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/img-1.png.png\" alt=\"stable-diffusion.png\"></p>\n<h2 id=\"scheduler\" style=\"position:relative;\"><a href=\"#scheduler\" aria-label=\"scheduler permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scheduler</h2>\n<p>Diffusion 모델 사용 시 스케줄러를 변경하여 생성할 수 있습니다. 스케줄러마다 장단점이 있기 때문에 여러 스케줄러를 사용해 비교해보는 것이 좋습니다. <code class=\"language-text\">Stable Diffusion</code>에서는 <code class=\"language-text\">PNDMScheduler</code>를 기본 스케줄러로 사용하고 있습니다. 스케줄러에 관한 자세한 정보는 <a href=\"https://huggingface.co/docs/diffusers/main/en/using-diffusers/schedulers\">해당 문서</a>에서 확인할 수 있습니다.</p>\n<p><code class=\"language-text\">Diffusers</code>에서는 다음과 같이 스케줄러를 변경할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> diffusers <span class=\"token keyword\">import</span> EulerDiscreteScheduler\n\npipeline<span class=\"token punctuation\">.</span>scheduler <span class=\"token operator\">=</span> EulerDiscreteScheduler<span class=\"token punctuation\">.</span>from_config<span class=\"token punctuation\">(</span>pipeline<span class=\"token punctuation\">.</span>scheduler<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">)</span></code></pre></div>","frontmatter":{"title":"Huggingface Diffusers 사용하기","date":"January 28, 2023"}}},"pageContext":{"slug":"/computer vision/Huggingface-Diffusers-사용하기/","previous":{"fields":{"slug":"/python/itertools-in-python/"},"frontmatter":{"title":"Itertools in Python"}},"next":null}}}